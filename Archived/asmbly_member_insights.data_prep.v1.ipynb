{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from tqdm.auto import tqdm\n",
    "from discourse_helpers import get_discourse_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"all_neon_members.csv\")\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woodshop_mentor_cols = [col for col in df.columns if \"woodshop mentor\" in col.lower()]\n",
    "orientation_cols = [col for col in df.columns if (\"orientation\" in col.lower() or \"facility\" in col.lower()) and \"_date\" not in col.lower()]\n",
    "woodshop_cols = [col for col in df.columns if \"woodshop\" in col.lower() and \"mentor\" not in col.lower() and \"specialty\" not in col.lower()]\n",
    "cnc_cols = [col for col in df.columns if \"cnc\" in col.lower() and \"tormach\" not in col.lower() and \"fusion\" not in col.lower() and \"topographic\" not in col.lower()]\n",
    "private_and_checkout = [col for col in df.columns if \"private\" in col.lower() or \"checkout\" in col.lower()]\n",
    "tormach_cols = [col for col in df.columns if \"tormach\" in col.lower() and \"fusion\" not in col.lower()]\n",
    "sanding_cols = [col for col in df.columns if \"sand\" in col.lower()]\n",
    "small_lasers_cols = [col for col in df.columns if \"small laser\" in col.lower() or \"blue\" in col.lower()]\n",
    "big_lasers_cols = [col for col in df.columns if \"laser\" in col.lower() and \"engrave\" not in col.lower() and \"small\" not in col.lower() and \"blue\" not in col.lower() and \"cancelled\" not in col.lower() and \"mother\" not in col.lower() and \"cnc\" not in col.lower()]\n",
    "wood_lathe = [col for col in df.columns if \"wood lathe\" in col.lower()]\n",
    "milling_cols = [col for col in df.columns if \"mill\" in col.lower() or \"intro to machining\" in col.lower()]\n",
    "specialty_tools_cols = [col for col in df.columns if \"specialty\" in col.lower() or \"domino\" in col.lower()]\n",
    "_3dp_cols = [col for col in df.columns if \"3d print\" in col.lower() and \"resin\" not in col.lower()]\n",
    "resin_3dp_cols = [col for col in df.columns if \"resin\" in col.lower() and \"epoxy\" not in col.lower()]\n",
    "fusion_cols = [col for col in df.columns if \"fusion\" in col.lower()]\n",
    "metal_lathe_cols = [col for col in df.columns if \"metal lathe\" in col.lower()]\n",
    "sublimation_cols = [col for col in df.columns if \"sublimation\" in col.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_update = {\n",
    "    \"woodshop_mentor_series\": woodshop_mentor_cols,\n",
    "    \"orientation_and_facility_tour\": orientation_cols,\n",
    "    \"woodshop_safety\": woodshop_cols,\n",
    "    \"cnc_router\": cnc_cols,\n",
    "    \"tormach\": tormach_cols,\n",
    "    \"stationary_sanders\": sanding_cols,\n",
    "    \"small_lasers\": small_lasers_cols,\n",
    "    \"big_lasers\": big_lasers_cols,\n",
    "    \"intro_wood_lathe\": wood_lathe,\n",
    "    \"intro_milling\": milling_cols,\n",
    "    \"specialty_tools\": specialty_tools_cols,\n",
    "    \"filament_3dp\": _3dp_cols,\n",
    "    \"resin_3dp\": resin_3dp_cols,\n",
    "    \"fusion\": fusion_cols,\n",
    "    \"metal_lathe\": metal_lathe_cols,\n",
    "    \"sublimation\": sublimation_cols\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in cols_to_update.items():\n",
    "\n",
    "    df.insert(len(df.columns), key, False)\n",
    "\n",
    "    for col in value:\n",
    "        df.loc[df[col] == True, key] = True\n",
    "\n",
    "    df.drop(value, axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Track Saw Update Class\", \"Cutting Board Build\", \"Basics of Hand Plane Use\", \"Aquaponics Discussion\", \"Low Volume Manufacturers Meetup\", \"Metal Shop Update\"], axis=1, inplace=True)\n",
    "\n",
    "cols_to_drop = []\n",
    "\n",
    "for col in df.columns:\n",
    "    count = df[col].value_counts()\n",
    "    if count.get(True, 0) < 10 and df.columns.get_loc(col) > 22:\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "df.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "new_columns = [columns[i].lower().replace(\" \", \"_\") for i in range(len(columns))]\n",
    "    \n",
    "column_dict = dict(zip(columns, new_columns)) \n",
    "    \n",
    "df.rename(columns = column_dict, inplace=True)\n",
    "\n",
    "df.rename(columns = {'cnc_project_-_machining_3d_topographic_maps': 'cnc_topo'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns.to_list()[df.columns.get_loc(\"total_dollars_spent\") + 1:]:\n",
    "    df[col] = df[col].fillna(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(df.columns.get_loc(\"discourse_id\"), \"discourse_posts\", 0)\n",
    "df.insert(df.columns.get_loc(\"discourse_id\"), \"discourse_read_time\", 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with aiohttp.ClientSession() as aio_session:\n",
    "    for row in tqdm(df.itertuples()):\n",
    "        if pd.isna(row.discourse_id):\n",
    "            continue\n",
    "\n",
    "        discourse_data = await get_discourse_data(aio_session, row.discourse_id)\n",
    "        if discourse_data is not None:\n",
    "            df.loc[row.Index, \"discourse_posts\"] = discourse_data[\"posts\"]\n",
    "            df.loc[row.Index, \"discourse_read_time\"] = discourse_data[\"reading time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(df.columns.get_loc(\"birthdate\") + 1, \"age\", np.nan)\n",
    "\n",
    "today = datetime.datetime.today()\n",
    "\n",
    "df.loc[df[\"birthdate\"].notna(), \"age\"] = (today - pd.to_datetime(df[\"birthdate\"])).dt.days // 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_neon_members.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(df.columns.get_loc(\"address\"), \"distance_from_asmbly\", np.nan)\n",
    "df.insert(df.columns.get_loc(\"address\"), \"time_from_asmbly\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "import requests\n",
    "from config import GOOGLE_MAPS_API_KEY\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "gmaps = googlemaps.Client(key=GOOGLE_MAPS_API_KEY, requests_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asmbly_geocode = gmaps.geocode('9701 Dessau Rd Ste 304, Austin, TX 78754')[0][\"geometry\"][\"location\"]\n",
    "\n",
    "print(asmbly_geocode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_distance_from_asmbly(\n",
    "        gmaps: googlemaps.Client,\n",
    "        user_address: str | type[np.nan],\n",
    "        city: str | type[np.nan],\n",
    "        state: str | type[np.nan],\n",
    "        zip: str | type[np.nan],\n",
    "        asmbly_address: list[float]\n",
    "    ) -> dict[str, float] | dict[str, type[np.nan]]:\n",
    "    if user_address is np.nan or city is np.nan or state is np.nan or zip is np.nan:\n",
    "        print(\"missing part of address\")\n",
    "        return {\"distance\": np.nan, \"time\": np.nan}\n",
    "    try:\n",
    "        routes = gmaps.directions(\n",
    "            origin=f\"{user_address}, {city}, {state} {zip}\",\n",
    "            destination=asmbly_address,\n",
    "            mode=\"driving\",\n",
    "            avoid=\"tolls\",\n",
    "            departure_time=datetime.datetime.now(),\n",
    "            region=\"US\",\n",
    "            language=\"en\",\n",
    "            units=\"metric\",\n",
    "            traffic_model=\"best_guess\",\n",
    "        )\n",
    "    except googlemaps.exceptions.ApiError as e:\n",
    "        print(e)\n",
    "        return {\"distance\": np.nan, \"time\": np.nan}\n",
    "    \n",
    "    try:\n",
    "        routes = routes[0]\n",
    "    except IndexError as e:\n",
    "        return {\"distance\": np.nan, \"time\": np.nan}\n",
    "    \n",
    "    distance = routes[\"legs\"][0][\"distance\"][\"value\"]\n",
    "    try:\n",
    "        time = routes[\"legs\"][0][\"duration_in_traffic\"][\"value\"]\n",
    "    except KeyError:\n",
    "        time = routes[\"legs\"][0][\"duration\"][\"value\"]\n",
    "\n",
    "    return {\"distance\": distance, \"time\": time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(df.itertuples()):\n",
    "    if pd.isna(row.address):\n",
    "        continue\n",
    "    result = get_distance_from_asmbly(gmaps, row.address, row.city, row.state, row.zip, asmbly_geocode)\n",
    "    df.loc[row.Index, \"distance_from_asmbly\"] = result[\"distance\"]\n",
    "    df.loc[row.Index, \"time_from_asmbly\"] = result[\"time\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"discourse_read_time\"] > 0.0, \"avg_monthly_discourse_read_time\"] = df[\"discourse_read_time\"] / df[\"membership_count\"]\n",
    "df.loc[df[\"discourse_posts\"] > 0.0, \"avg_monthly_discourse_posts\"] = df[\"discourse_posts\"] / df[\"membership_count\"]\n",
    "\n",
    "df[\"avg_monthly_discourse_posts\"].fillna(0, inplace=True)\n",
    "df[\"avg_monthly_discourse_read_time\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"waiver_date\"].notna(), \"waiver_signed\"] = True\n",
    "df[\"waiver_signed\"].fillna(False, inplace=True)\n",
    "\n",
    "df.loc[(df[\"orientation_date\"].notna()) | (df[\"orientation_and_facility_tour\"] == True), \"orientation_attended\"] = True\n",
    "df[\"orientation_attended\"].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skedda_df = pd.DataFrame()\n",
    "for csv in [\"skedda_bookings_feb2020_to_feb2021.csv\", \"skedda_bookings_feb2021_to_feb2022.csv\", \"skedda_bookings_feb2022_to_feb2023.csv\", \"skedda_bookings_feb2023_to_feb2024.csv\"]:\n",
    "    csv_df = pd.read_csv(csv)\n",
    "    skedda_df = pd.concat([skedda_df, csv_df])\n",
    "\n",
    "skedda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skedda_df = skedda_df[[\"Duration (minutes)\", \"Holder first name\", \"Holder last name\", \"Holder email\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = skedda_df.groupby([\"Holder email\", \"Holder first name\", \"Holder last name\"], as_index=False)[\"Duration (minutes)\"].agg(booking_count = \"count\", total_booking_minutes = \"sum\").sort_values(by=\"total_booking_minutes\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.drop(234, inplace=True)\n",
    "\n",
    "grouped_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.copy_on_write = True\n",
    "concat_df = grouped_df[[\"Holder email\", \"total_booking_minutes\", \"booking_count\"]]\n",
    "concat_df.rename(columns={\"Holder email\": \"email\"}, inplace=True)\n",
    "\n",
    "concat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, concat_df, on=\"email\", how=\"left\")\n",
    "df.fillna({\"total_booking_minutes\": 0.0, \"booking_count\": 0.0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"total_booking_minutes\"] > 0.0, \"avg_monthly_booking_minutes\"] = df[\"total_booking_minutes\"] / df[\"membership_count\"]\n",
    "df.loc[df[\"booking_count\"] > 0.0, \"avg_monthly_booking_count\"] = df[\"booking_count\"] / df[\"membership_count\"]\n",
    "\n",
    "df.fillna({\"avg_monthly_booking_minutes\": 0.0, \"avg_monthly_booking_count\": 0.0}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(np.inf, 0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"neon_members_with_distance.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"neon_members_with_distance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"neon_id\", \"first_name\", \"last_name\", \"email\", \"address\", \"city\", \"state\", \"zip\", \"phone\", \"birthdate\", \"openpath_id\", \"discourse_id\", \"waiver_date\", \"orientation_date\", \"first_membership_start\", \"last_membership_end\"]\n",
    "\n",
    "cleaned_df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "cleaned_df.to_csv(\"asmbly_cleaned_member_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AsmblyMakerspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
