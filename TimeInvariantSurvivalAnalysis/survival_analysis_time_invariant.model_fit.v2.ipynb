{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lifelines import CoxPHFitter\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sksurv.ensemble import RandomSurvivalForest, GradientBoostingSurvivalAnalysis\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import as_cumulative_dynamic_auc_scorer\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng=np.random.RandomState(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_members_cleaned_short_form.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"gender\", \"referral_source\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Cox PH analysis, we'll need to one hot encode the cateogrical variables, and min-max scale the \n",
    "continuous variables. The Lifelines documentation doesn't state whether variable scaling is handled\n",
    "automatically, so we'll do it ourselves to be safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[\"referral_source\", \"gender\"])\n",
    "\n",
    "#df.drop(columns=[\"neon_id\"], inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cox = CoxPHFitter(penalizer=0.1)\n",
    "cox.fit(\n",
    "    df,\n",
    "    duration_col = \"duration\",\n",
    "    event_col = \"membership_cancelled\",\n",
    "    robust=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,16))\n",
    "\n",
    "cox.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cox.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_members_cleaned_short_form.csv')\n",
    "#df = pd.get_dummies(df, columns=[\"referral_source\", \"gender\"], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"membership_cancelled\", \"duration\", \"total_dollars_spent\", \"num_classes_attended\"])\n",
    "y = df[[\"membership_cancelled\", \"duration\"]]\n",
    "y = Surv.from_dataframe('membership_cancelled', 'duration', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=rng, stratify=y[\"membership_cancelled\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = set(np.percentile(y[\"duration\"], np.linspace(5, 81, 10)))\n",
    "times = np.array(list(times), dtype=\"float64\")\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsf = RandomSurvivalForest(\n",
    "    n_estimators=2000, min_samples_split=15, min_samples_leaf=13, n_jobs=-1, random_state=rng, oob_score=True\n",
    ")\n",
    "rsf.fit(X_train, y_train)\n",
    "\n",
    "rsf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsf_grid = RandomSurvivalForest(random_state=rng, oob_score=True, n_jobs=-1)\n",
    "param_distributions={\n",
    "        \"estimator__n_estimators\": [200, 1000, 2000, 3000],\n",
    "        \"estimator__min_samples_split\": stats.uniform(0,0.5),\n",
    "        \"estimator__min_samples_leaf\": stats.uniform(0,0.5),\n",
    "        \"estimator__max_depth\": [None, 1, 5]\n",
    "    }\n",
    "\n",
    "rsf_grid = RandomizedSearchCV(\n",
    "    as_cumulative_dynamic_auc_scorer(rsf_grid, times=times),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50\n",
    ")\n",
    "\n",
    "rsf_grid.fit(X_train, y_train)\n",
    "\n",
    "cindex = rsf_grid.score(X_test, y_test)\n",
    "print(\"Performance on test set\", round(cindex, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingSurvivalAnalysis(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.5,\n",
    "    max_depth=1,\n",
    "    random_state=rng\n",
    ")\n",
    "\n",
    "cross_val = cross_val_score(gbm, X_train, y_train)\n",
    "print(cross_val.mean(), cross_val.std())\n",
    "\n",
    "gbm.fit(X_train, y_train)\n",
    "gbm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingSurvivalAnalysis(random_state=rng)\n",
    "param_distributions={\n",
    "        \"estimator__n_estimators\": [100, 500, 1000],\n",
    "        \"estimator__learning_rate\": stats.loguniform(0.1,1),\n",
    "        \"estimator__subsample\": stats.uniform(0.5,0.5),\n",
    "        \"estimator__max_depth\": [1,3,5]\n",
    "    }\n",
    "\n",
    "grid_search = RandomizedSearchCV(\n",
    "    as_cumulative_dynamic_auc_scorer(gbm, times=times),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "cindex = grid_search.score(X_test, y_test)\n",
    "print(\"Performance on test set\", round(cindex, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "\n",
    "rsf_chf_funcs = rsf.predict_cumulative_hazard_function(X_test, return_array=False)\n",
    "\n",
    "rsf_risk_scores = np.row_stack([chf(times) for chf in rsf_chf_funcs])\n",
    "\n",
    "rsf_auc, rsf_mean_auc = cumulative_dynamic_auc(y_train, y_test, rsf_risk_scores, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times, rsf_auc, \"o-\", label=f\"RSF (mean AUC = {rsf_mean_auc:.3f})\")\n",
    "plt.xlabel(\"Months since joining\")\n",
    "plt.ylabel(\"time-dependent AUC\")\n",
    "plt.legend(loc=\"lower center\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_search.predict(X)\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame(pred, columns=[\"risk_score\"])], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"membership_cancelled\"] == False].sort_values(by=\"risk_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(rsf, X_test, y_test, n_repeats=15, random_state=rng)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        k: result[k]\n",
    "        for k in (\n",
    "            \"importances_mean\",\n",
    "            \"importances_std\",\n",
    "        )\n",
    "    },\n",
    "    index=X_test.columns,\n",
    ").sort_values(by=\"importances_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(gbm, X_test, y_test, n_repeats=15, random_state=rng)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        k: result[k]\n",
    "        for k in (\n",
    "            \"importances_mean\",\n",
    "            \"importances_std\",\n",
    "        )\n",
    "    },\n",
    "    index=X_test.columns,\n",
    ").sort_values(by=\"importances_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AsmblyMakerspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
