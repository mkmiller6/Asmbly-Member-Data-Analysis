{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lifelines import CoxPHFitter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sksurv.ensemble import RandomSurvivalForest, GradientBoostingSurvivalAnalysis\n",
    "#from sksurv.preprocessing import OneHotEncoder\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import as_cumulative_dynamic_auc_scorer\n",
    "import scipy.stats as stats\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng=np.random.RandomState(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_members_short_form.csv')\n",
    "\n",
    "drop_cols = [\"num_classes_attended\", \"total_dollars_spent\", \"neon_id\",\"first_name\", \"last_name\", \"email\"]\n",
    "num_cols = [\"num_classes_before_joining\", \"time_from_asmbly\", \"age\"]\n",
    "\n",
    "gender_cats = [\"Male\", \"Female\", \"Non-binary\", \"Other\", \"Prefer not to answer\"]\n",
    "referral_cats = [\n",
    "    \"Google\",\n",
    "    \"Facebook\",\n",
    "    \"Instagram\",\n",
    "    \"Friend/Coworker\",\n",
    "    \"MeetUp\",\n",
    "    \"Asmbly Maker Market\",\n",
    "    \"Texas Woodworking Festival\",\n",
    "    \"Other\",\n",
    "]\n",
    "\n",
    "categories = [\n",
    "    ('gender', gender_cats),\n",
    "    ('referral_source', referral_cats),\n",
    "]\n",
    "\n",
    "ohe_cats = [x[1] for x in categories]\n",
    "ohe_columns = [x[0] for x in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_label_split(df: pd.DataFrame):\n",
    "    X = df.drop(columns=[\"membership_cancelled\", \"duration\"])\n",
    "    y = df[[\"membership_cancelled\", \"duration\"]]\n",
    "    y = Surv.from_dataframe('membership_cancelled', 'duration', y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = attr_label_split(df)\n",
    "\n",
    "num_transforms = [\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    #('scaler', RobustScaler()),\n",
    "]\n",
    "num_pipeline = Pipeline(num_transforms)\n",
    "\n",
    "cat_transforms = [\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(\n",
    "            categories=ohe_cats,\n",
    "            handle_unknown='ignore'\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "cat_pipeline = Pipeline(cat_transforms)\n",
    "\n",
    "all_transforms = [\n",
    "    ('numeric', num_pipeline, num_cols),\n",
    "    ('categorical', cat_pipeline, ohe_columns),\n",
    "    ('drops', 'drop', drop_cols),\n",
    "]\n",
    "\n",
    "full_transform_pipeline = ColumnTransformer(all_transforms, remainder='passthrough')\n",
    "\n",
    "X_transformed = full_transform_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.20, random_state=rng, stratify=y[\"membership_cancelled\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = set(np.percentile(y[\"duration\"], np.linspace(5, 81, 10)))\n",
    "times = np.array(list(times), dtype=\"float64\")\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsf = RandomSurvivalForest(\n",
    "    n_estimators=2000, min_samples_split=15, min_samples_leaf=13, n_jobs=-1, random_state=rng, oob_score=True\n",
    ")\n",
    "#rsf.fit(X_train, y_train)\n",
    "rsf.fit(X_transformed, y)\n",
    "#rsf.score(X_test, y_test)\n",
    "rsf.score(X_transformed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsf_grid = RandomSurvivalForest(random_state=rng, oob_score=True, n_jobs=-1)\n",
    "param_distributions={\n",
    "        \"estimator__n_estimators\": [200, 1000, 2000, 3000],\n",
    "        \"estimator__min_samples_split\": stats.uniform(0,0.5),\n",
    "        \"estimator__min_samples_leaf\": stats.uniform(0,0.5),\n",
    "        \"estimator__max_depth\": [None, 1, 5]\n",
    "    }\n",
    "\n",
    "rsf_grid = RandomizedSearchCV(\n",
    "    as_cumulative_dynamic_auc_scorer(rsf_grid, times=times),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50\n",
    ")\n",
    "\n",
    "rsf_grid.fit(X_train, y_train)\n",
    "\n",
    "cindex = rsf_grid.score(X_test, y_test)\n",
    "print(\"Performance on test set\", round(cindex, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingSurvivalAnalysis(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.5,\n",
    "    max_depth=1,\n",
    "    random_state=rng\n",
    ")\n",
    "\n",
    "cross_val = cross_val_score(gbm, X_transformed, y)\n",
    "print(cross_val.mean(), cross_val.std())\n",
    "\n",
    "gbm.fit(X_train, y_train)\n",
    "gbm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingSurvivalAnalysis(random_state=rng, max_depth=1)\n",
    "param_grid={\n",
    "        \"estimator__n_estimators\": [100, 300, 500, 1000],\n",
    "        \"estimator__learning_rate\": [0.1, 0.5, 1],\n",
    "        \"estimator__subsample\": [0.5, 0.75, 1],\n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    as_cumulative_dynamic_auc_scorer(gbm, times=times),\n",
    "    param_grid=param_grid\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "auc = grid_search.score(X_test, y_test)\n",
    "print(\"Performance on test set (AUC)\", round(auc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "\n",
    "rsf_chf_funcs = rsf.predict_cumulative_hazard_function(X_test, return_array=False)\n",
    "\n",
    "rsf_risk_scores = np.row_stack([chf(times) for chf in rsf_chf_funcs])\n",
    "\n",
    "rsf_auc, rsf_mean_auc = cumulative_dynamic_auc(y_train, y_test, rsf_risk_scores, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times, rsf_auc, \"o-\", label=f\"RSF (mean AUC = {rsf_mean_auc:.3f})\")\n",
    "plt.xlabel(\"Months since joining\")\n",
    "plt.ylabel(\"time-dependent AUC\")\n",
    "plt.legend(loc=\"lower center\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_search.predict(X_transformed)\n",
    "\n",
    "new_df = pd.concat([df, pd.DataFrame(pred, columns=[\"risk_score\"])], axis=1)\n",
    "\n",
    "risk_df = new_df[new_df[\"membership_cancelled\"] == False].sort_values(by=\"risk_score\", ascending=False)\n",
    "\n",
    "risk_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(rsf, X_test, y_test, n_repeats=15, random_state=rng)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        k: result[k]\n",
    "        for k in (\n",
    "            \"importances_mean\",\n",
    "            \"importances_std\",\n",
    "        )\n",
    "    },\n",
    "    index=X_test.columns,\n",
    ").sort_values(by=\"importances_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_transform_pipeline.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(grid_search, X_test, y_test, n_repeats=15, random_state=rng)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        k: result[k]\n",
    "        for k in (\n",
    "            \"importances_mean\",\n",
    "            \"importances_std\",\n",
    "        )\n",
    "    },\n",
    "    index=full_transform_pipeline.get_feature_names_out(),\n",
    ").sort_values(by=\"importances_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transform_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(full_transform_pipeline, f)\n",
    "\n",
    "with open('gbm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_search, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transform_pipeline.pkl', 'rb') as f:\n",
    "    new_pipeline = pickle.load(f)\n",
    "\n",
    "with open('gbm_model.pkl', 'rb') as f:\n",
    "    new_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = new_pipeline.transform(X)\n",
    "\n",
    "new_preds = new_model.predict(new_x)\n",
    "\n",
    "new_df = pd.concat([df, pd.DataFrame(new_preds, columns=[\"risk_score\"])], axis=1)\n",
    "\n",
    "new_risk_df = new_df[new_df[\"membership_cancelled\"] == False].sort_values(by=\"risk_score\", ascending=False)\n",
    "\n",
    "new_risk_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_risk_df = pd.concat([df, pd.DataFrame(new_preds, columns=[\"risk_score\"])], axis=1).sort_values(by=\"risk_score\", ascending=False)\n",
    "\n",
    "full_risk_df.to_csv('asmbly_churn_risk.csv')\n",
    "\n",
    "full_risk_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AsmblyMakerspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
